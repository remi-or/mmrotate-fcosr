{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from argparse import Namespace\n",
    "from tools.train import main\n",
    "\n",
    "sys.stdout.fileno = lambda : 1\n",
    "\n",
    "args = Namespace(**dict(\n",
    "    config=\"configs/fcosr/fcosr_res50_32x4d_fpn_3x_dota10_single.py\",\n",
    "    work_dir=None,\n",
    "    resume_from=None,\n",
    "    auto_resume=True,\n",
    "    no_validate=True,\n",
    "    gpus=1,\n",
    "    gpu_ids=None,\n",
    "    seed=42,\n",
    "    diff_seed=False,\n",
    "    deterministic=True,\n",
    "    cfg_options=None,\n",
    "    launcher='none'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\meri2\\Documents\\mmrotate-fcosr\\mmrotate\\utils\\setup_env.py:38: UserWarning: Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed.\n",
      "  warnings.warn(\n",
      "c:\\Users\\meri2\\Documents\\mmrotate-fcosr\\mmrotate\\utils\\setup_env.py:48: UserWarning: Setting MKL_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed.\n",
      "  warnings.warn(\n",
      "2022-05-10 16:37:23,960 - mmrotate - INFO - Environment info:\n",
      "------------------------------------------------------------\n",
      "sys.platform: win32\n",
      "Python: 3.9.12 (main, Apr  4 2022, 05:22:27) [MSC v.1916 64 bit (AMD64)]\n",
      "CUDA available: True\n",
      "GPU 0: NVIDIA GeForce RTX 3070 Laptop GPU\n",
      "CUDA_HOME: C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v11.3\n",
      "NVCC: Cuda compilation tools, release 11.3, V11.3.58\n",
      "MSVC: Microsoft (R) C/C++ Optimizing Compiler Version 19.29.30138 for x64\n",
      "GCC: n/a\n",
      "PyTorch: 1.11.0\n",
      "PyTorch compiling details: PyTorch built with:\n",
      "  - C++ Version: 199711\n",
      "  - MSVC 192829337\n",
      "  - Intel(R) Math Kernel Library Version 2020.0.2 Product Build 20200624 for Intel(R) 64 architecture applications\n",
      "  - Intel(R) MKL-DNN v2.5.2 (Git Hash a9302535553c73243c632ad3c4c80beec3d19a1e)\n",
      "  - OpenMP 2019\n",
      "  - LAPACK is enabled (usually provided by MKL)\n",
      "  - CPU capability usage: AVX2\n",
      "  - CUDA Runtime 11.3\n",
      "  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37\n",
      "  - CuDNN 8.2\n",
      "  - Magma 2.5.4\n",
      "  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.3, CUDNN_VERSION=8.2.0, CXX_COMPILER=C:/cb/pytorch_1000000000000/work/tmp_bin/sccache-cl.exe, CXX_FLAGS=/DWIN32 /D_WINDOWS /GR /EHsc /w /bigobj -DUSE_PTHREADPOOL -openmp:experimental -IC:/cb/pytorch_1000000000000/work/mkl/include -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOCUPTI -DUSE_FBGEMM -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.11.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=OFF, USE_MPI=OFF, USE_NCCL=OFF, USE_NNPACK=OFF, USE_OPENMP=ON, USE_ROCM=OFF, \n",
      "\n",
      "TorchVision: 0.12.0\n",
      "OpenCV: 4.5.5\n",
      "MMCV: 1.5.0\n",
      "MMCV Compiler: MSVC 192930138\n",
      "MMCV CUDA Compiler: 11.3\n",
      "MMRotate: 0.3.0+2767622\n",
      "------------------------------------------------------------\n",
      "\n",
      "2022-05-10 16:37:24,595 - mmrotate - INFO - Distributed training: False\n",
      "2022-05-10 16:37:25,329 - mmrotate - INFO - Config:\n",
      "image_size = (1024, 1024)\n",
      "angle_version = 'oc'\n",
      "dataset_type = 'DOTADataset'\n",
      "data_root = 'C:/Users/meri2/Documents/DOTA_1.0/split_ms_dota/'\n",
      "img_norm_cfg = dict(\n",
      "    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)\n",
      "train_pipeline = [\n",
      "    dict(type='LoadImageFromFile'),\n",
      "    dict(type='LoadAnnotations', with_bbox=True),\n",
      "    dict(type='RResize', img_scale=(1024, 1024)),\n",
      "    dict(type='RRandomFlip', flip_ratio=0.5, version='oc'),\n",
      "    dict(\n",
      "        type='Normalize',\n",
      "        mean=[123.675, 116.28, 103.53],\n",
      "        std=[58.395, 57.12, 57.375],\n",
      "        to_rgb=True),\n",
      "    dict(type='Pad', size_divisor=32),\n",
      "    dict(type='DefaultFormatBundle'),\n",
      "    dict(type='Collect', keys=['img', 'gt_bboxes', 'gt_labels'])\n",
      "]\n",
      "test_pipeline = [\n",
      "    dict(type='LoadImageFromFile'),\n",
      "    dict(\n",
      "        type='MultiScaleFlipAug',\n",
      "        img_scale=(1024, 1024),\n",
      "        flip=False,\n",
      "        transforms=[\n",
      "            dict(type='RResize'),\n",
      "            dict(\n",
      "                type='Normalize',\n",
      "                mean=[123.675, 116.28, 103.53],\n",
      "                std=[58.395, 57.12, 57.375],\n",
      "                to_rgb=True),\n",
      "            dict(type='Pad', size_divisor=32),\n",
      "            dict(type='DefaultFormatBundle'),\n",
      "            dict(type='Collect', keys=['img'])\n",
      "        ])\n",
      "]\n",
      "data = dict(\n",
      "    samples_per_gpu=2,\n",
      "    workers_per_gpu=2,\n",
      "    train=dict(\n",
      "        type='DOTADataset',\n",
      "        ann_file=\n",
      "        'C:/Users/meri2/Documents/DOTA_1.0/split_ms_dota/trainval/annfiles/',\n",
      "        img_prefix=\n",
      "        'C:/Users/meri2/Documents/DOTA_1.0/split_ms_dota/trainval/images/',\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(type='LoadAnnotations', with_bbox=True),\n",
      "            dict(type='RResize', img_scale=(1024, 1024)),\n",
      "            dict(type='RRandomFlip', flip_ratio=0.5, version='oc'),\n",
      "            dict(\n",
      "                type='Normalize',\n",
      "                mean=[123.675, 116.28, 103.53],\n",
      "                std=[58.395, 57.12, 57.375],\n",
      "                to_rgb=True),\n",
      "            dict(type='Pad', size_divisor=32),\n",
      "            dict(type='DefaultFormatBundle'),\n",
      "            dict(type='Collect', keys=['img', 'gt_bboxes', 'gt_labels'])\n",
      "        ]),\n",
      "    val=dict(\n",
      "        type='DOTADataset',\n",
      "        ann_file=\n",
      "        'C:/Users/meri2/Documents/DOTA_1.0/split_ms_dota/trainval/annfiles/',\n",
      "        img_prefix=\n",
      "        'C:/Users/meri2/Documents/DOTA_1.0/split_ms_dota/trainval/images/',\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(\n",
      "                type='MultiScaleFlipAug',\n",
      "                img_scale=(1024, 1024),\n",
      "                flip=False,\n",
      "                transforms=[\n",
      "                    dict(type='RResize'),\n",
      "                    dict(\n",
      "                        type='Normalize',\n",
      "                        mean=[123.675, 116.28, 103.53],\n",
      "                        std=[58.395, 57.12, 57.375],\n",
      "                        to_rgb=True),\n",
      "                    dict(type='Pad', size_divisor=32),\n",
      "                    dict(type='DefaultFormatBundle'),\n",
      "                    dict(type='Collect', keys=['img'])\n",
      "                ])\n",
      "        ]),\n",
      "    test=dict(\n",
      "        type='DOTADataset',\n",
      "        ann_file='C:/Users/meri2/Documents/DOTA_1.0/split_ms_dota/test/images/',\n",
      "        img_prefix=\n",
      "        'C:/Users/meri2/Documents/DOTA_1.0/split_ms_dota/test/images/',\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(\n",
      "                type='MultiScaleFlipAug',\n",
      "                img_scale=(1024, 1024),\n",
      "                flip=False,\n",
      "                transforms=[\n",
      "                    dict(type='RResize'),\n",
      "                    dict(\n",
      "                        type='Normalize',\n",
      "                        mean=[123.675, 116.28, 103.53],\n",
      "                        std=[58.395, 57.12, 57.375],\n",
      "                        to_rgb=True),\n",
      "                    dict(type='Pad', size_divisor=32),\n",
      "                    dict(type='DefaultFormatBundle'),\n",
      "                    dict(type='Collect', keys=['img'])\n",
      "                ])\n",
      "        ]))\n",
      "evaluation = dict(interval=36, metric='mAP')\n",
      "optimizer = dict(type='SGD', lr=0.01, momentum=0.9, weight_decay=0.0001)\n",
      "optimizer_config = dict(grad_clip=dict(max_norm=35, norm_type=2))\n",
      "lr_config = dict(\n",
      "    policy='step',\n",
      "    warmup='linear',\n",
      "    warmup_iters=500,\n",
      "    warmup_ratio=0.3333333333333333,\n",
      "    step=[24, 33])\n",
      "runner = dict(type='EpochBasedRunner', max_epochs=36)\n",
      "checkpoint_config = dict(interval=1)\n",
      "log_config = dict(interval=50, hooks=[dict(type='TextLoggerHook')])\n",
      "dist_params = dict(backend='nccl')\n",
      "log_level = 'INFO'\n",
      "load_from = None\n",
      "resume_from = None\n",
      "workflow = [('train', 1)]\n",
      "opencv_num_threads = 0\n",
      "mp_start_method = 'fork'\n",
      "num_gpus = 1\n",
      "model = dict(\n",
      "    type='FCOSR',\n",
      "    backbone=dict(\n",
      "        type='ResNeXt',\n",
      "        groups=32,\n",
      "        base_width=4,\n",
      "        depth=50,\n",
      "        num_stages=4,\n",
      "        out_indices=(1, 2, 3),\n",
      "        frozen_stages=1,\n",
      "        style='pytorch',\n",
      "        init_cfg=dict(\n",
      "            type='Pretrained', checkpoint='torchvision://resnext50_32x4d')),\n",
      "    neck=dict(\n",
      "        type='FPN',\n",
      "        in_channels=[512, 1024, 2048],\n",
      "        out_channels=256,\n",
      "        start_level=0,\n",
      "        num_outs=5,\n",
      "        add_extra_convs='on_output',\n",
      "        relu_before_extra_convs=True),\n",
      "    bbox_head=dict(\n",
      "        type='FCOSRHead',\n",
      "        num_classes=15,\n",
      "        in_channels=256,\n",
      "        feat_channels=256,\n",
      "        stacked_convs=4,\n",
      "        strides=(8, 16, 32, 64, 128),\n",
      "        regress_ranges=((-1, 64), (64, 128), (128, 256), (256, 512),\n",
      "                        (512, 100000000)),\n",
      "        conv_cfg=dict(type='Conv2d'),\n",
      "        norm_cfg=dict(type='GN', num_groups=32, requires_grad=True),\n",
      "        assigner=dict(\n",
      "            type='GaussianAssigner',\n",
      "            gauss_factor=12.0,\n",
      "            inside_ellipsis_thresh=0.23,\n",
      "            epsilon=1e-06),\n",
      "        cls_loss=dict(\n",
      "            type='QualityFocalLoss',\n",
      "            use_sigmoid=True,\n",
      "            beta=2.0,\n",
      "            reduction='mean',\n",
      "            loss_weight=1.0),\n",
      "        cls_scores='iou',\n",
      "        reg_loss=dict(type='ProbiouLoss', mode='l1', loss_weight=1.0),\n",
      "        reg_weights='iou',\n",
      "        init_cfg=dict(\n",
      "            type='Normal',\n",
      "            layer='Conv2d',\n",
      "            std=0.01,\n",
      "            override=dict(\n",
      "                type='Normal',\n",
      "                name='cls_logits_conv',\n",
      "                std=0.01,\n",
      "                bias_prob=0.01))),\n",
      "    train_cfg=dict(gamma=2.0, alpha=0.25),\n",
      "    test_cfg=dict(\n",
      "        nms_pre=2000,\n",
      "        min_bbox_size=8,\n",
      "        score_thr=0.1,\n",
      "        nms=0.1,\n",
      "        max_per_img=2000,\n",
      "        extra_nms=0.85,\n",
      "        rotations=[]))\n",
      "custom_hooks = [\n",
      "    dict(type='NumClassCheckHook'),\n",
      "    dict(type='GradientCumulativeOptimizerHook', cumulative_iters=2)\n",
      "]\n",
      "work_dir = 'work_dirs/DOTA10/FCOSR-M/FCOSR_rx50_32x4d_fpn_3x_dota10_single'\n",
      "find_unused_parameters = True\n",
      "gpu_ids = range(0, 1)\n",
      "auto_resume = True\n",
      "\n",
      "2022-05-10 16:37:25,330 - mmrotate - INFO - Set random seed to 42, deterministic: True\n",
      "2022-05-10 16:37:25,772 - mmrotate - INFO - initialize ResNeXt with init_cfg {'type': 'Pretrained', 'checkpoint': 'torchvision://resnext50_32x4d'}\n",
      "2022-05-10 16:37:25,773 - mmcv - INFO - load model from: torchvision://resnext50_32x4d\n",
      "2022-05-10 16:37:25,774 - mmcv - INFO - load checkpoint from torchvision path: torchvision://resnext50_32x4d\n",
      "2022-05-10 16:37:25,878 - mmcv - WARNING - The model and loaded state dict do not match exactly\n",
      "\n",
      "unexpected key in source state_dict: fc.weight, fc.bias\n",
      "\n",
      "2022-05-10 16:37:25,909 - mmrotate - INFO - initialize FPN with init_cfg {'type': 'Xavier', 'layer': 'Conv2d', 'distribution': 'uniform'}\n",
      "2022-05-10 16:37:25,942 - mmrotate - INFO - initialize FCOSRHead with init_cfg {'type': 'Normal', 'layer': 'Conv2d', 'std': 0.01, 'override': {'type': 'Normal', 'name': 'cls_logits_conv', 'std': 0.01, 'bias_prob': 0.01}}\n",
      "c:\\Users\\meri2\\Documents\\mmrotate-fcosr\\mmrotate\\utils\\misc.py:30: UserWarning: There are no checkpoints in the path.\n",
      "  warnings.warn('There are no checkpoints in the path.')\n",
      "2022-05-10 16:38:10,961 - mmrotate - INFO - Start running, host: meri2@Ror-laptop, work_dir: c:\\Users\\meri2\\Documents\\mmrotate-fcosr\\work_dirs\\DOTA10\\FCOSR-M\\FCOSR_rx50_32x4d_fpn_3x_dota10_single\n",
      "2022-05-10 16:38:10,961 - mmrotate - INFO - Hooks will be executed in the following order:\n",
      "before_run:\n",
      "(VERY_HIGH   ) StepLrUpdaterHook                  \n",
      "(NORMAL      ) CheckpointHook                     \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "before_train_epoch:\n",
      "(VERY_HIGH   ) StepLrUpdaterHook                  \n",
      "(NORMAL      ) NumClassCheckHook                  \n",
      "(LOW         ) IterTimerHook                      \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "before_train_iter:\n",
      "(VERY_HIGH   ) StepLrUpdaterHook                  \n",
      "(LOW         ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_train_iter:\n",
      "(ABOVE_NORMAL) OptimizerHook                      \n",
      "(NORMAL      ) CheckpointHook                     \n",
      "(NORMAL      ) GradientCumulativeOptimizerHook    \n",
      "(LOW         ) IterTimerHook                      \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "after_train_epoch:\n",
      "(NORMAL      ) CheckpointHook                     \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "before_val_epoch:\n",
      "(NORMAL      ) NumClassCheckHook                  \n",
      "(LOW         ) IterTimerHook                      \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "before_val_iter:\n",
      "(LOW         ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_val_iter:\n",
      "(LOW         ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_val_epoch:\n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "after_run:\n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "2022-05-10 16:38:10,962 - mmrotate - INFO - workflow: [('train', 1)], max: 36 epochs\n",
      "2022-05-10 16:38:10,962 - mmrotate - INFO - Checkpoints will be saved to c:\\Users\\meri2\\Documents\\mmrotate-fcosr\\work_dirs\\DOTA10\\FCOSR-M\\FCOSR_rx50_32x4d_fpn_3x_dota10_single by HardDiskBackend.\n",
      "2022-05-10 16:38:30,610 - mmrotate - WARNING - GradientCumulativeOptimizerHook may slightly decrease performance if the model has BatchNorm layers.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Trying to backward through the graph a second time (or directly access saved tensors after they have already been freed). Saved intermediate values of the graph are freed when you call .backward() or autograd.grad(). Specify retain_graph=True if you need to backward through the graph a second time or if you need to access saved tensors after calling backward.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\meri2\\Documents\\mmrotate-fcosr\\test_fcosr.ipynb Cell 2'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/meri2/Documents/mmrotate-fcosr/test_fcosr.ipynb#ch0000001?line=0'>1</a>\u001b[0m main(args)\n",
      "File \u001b[1;32mc:\\Users\\meri2\\Documents\\mmrotate-fcosr\\tools\\train.py:181\u001b[0m, in \u001b[0;36mmain\u001b[1;34m(args)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/meri2/Documents/mmrotate-fcosr/tools/train.py?line=178'>179</a>\u001b[0m \u001b[39m# add an attribute for visualization convenience\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/meri2/Documents/mmrotate-fcosr/tools/train.py?line=179'>180</a>\u001b[0m model\u001b[39m.\u001b[39mCLASSES \u001b[39m=\u001b[39m datasets[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mCLASSES\n\u001b[1;32m--> <a href='file:///c%3A/Users/meri2/Documents/mmrotate-fcosr/tools/train.py?line=180'>181</a>\u001b[0m train_detector(\n\u001b[0;32m    <a href='file:///c%3A/Users/meri2/Documents/mmrotate-fcosr/tools/train.py?line=181'>182</a>\u001b[0m     model,\n\u001b[0;32m    <a href='file:///c%3A/Users/meri2/Documents/mmrotate-fcosr/tools/train.py?line=182'>183</a>\u001b[0m     datasets,\n\u001b[0;32m    <a href='file:///c%3A/Users/meri2/Documents/mmrotate-fcosr/tools/train.py?line=183'>184</a>\u001b[0m     cfg,\n\u001b[0;32m    <a href='file:///c%3A/Users/meri2/Documents/mmrotate-fcosr/tools/train.py?line=184'>185</a>\u001b[0m     distributed\u001b[39m=\u001b[39;49mdistributed,\n\u001b[0;32m    <a href='file:///c%3A/Users/meri2/Documents/mmrotate-fcosr/tools/train.py?line=185'>186</a>\u001b[0m     validate\u001b[39m=\u001b[39;49m(\u001b[39mnot\u001b[39;49;00m args\u001b[39m.\u001b[39;49mno_validate),\n\u001b[0;32m    <a href='file:///c%3A/Users/meri2/Documents/mmrotate-fcosr/tools/train.py?line=186'>187</a>\u001b[0m     timestamp\u001b[39m=\u001b[39;49mtimestamp,\n\u001b[0;32m    <a href='file:///c%3A/Users/meri2/Documents/mmrotate-fcosr/tools/train.py?line=187'>188</a>\u001b[0m     meta\u001b[39m=\u001b[39;49mmeta)\n",
      "File \u001b[1;32mc:\\Users\\meri2\\Documents\\mmrotate-fcosr\\mmrotate\\apis\\train.py:141\u001b[0m, in \u001b[0;36mtrain_detector\u001b[1;34m(model, dataset, cfg, distributed, validate, timestamp, meta)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/meri2/Documents/mmrotate-fcosr/mmrotate/apis/train.py?line=138'>139</a>\u001b[0m \u001b[39melif\u001b[39;00m cfg\u001b[39m.\u001b[39mload_from:\n\u001b[0;32m    <a href='file:///c%3A/Users/meri2/Documents/mmrotate-fcosr/mmrotate/apis/train.py?line=139'>140</a>\u001b[0m     runner\u001b[39m.\u001b[39mload_checkpoint(cfg\u001b[39m.\u001b[39mload_from)\n\u001b[1;32m--> <a href='file:///c%3A/Users/meri2/Documents/mmrotate-fcosr/mmrotate/apis/train.py?line=140'>141</a>\u001b[0m runner\u001b[39m.\u001b[39;49mrun(data_loaders, cfg\u001b[39m.\u001b[39;49mworkflow)\n",
      "File \u001b[1;32mc:\\Users\\meri2\\.conda\\envs\\MMRotate\\lib\\site-packages\\mmcv\\runner\\epoch_based_runner.py:127\u001b[0m, in \u001b[0;36mEpochBasedRunner.run\u001b[1;34m(self, data_loaders, workflow, max_epochs, **kwargs)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/meri2/.conda/envs/MMRotate/lib/site-packages/mmcv/runner/epoch_based_runner.py?line=124'>125</a>\u001b[0m             \u001b[39mif\u001b[39;00m mode \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mepoch \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_max_epochs:\n\u001b[0;32m    <a href='file:///c%3A/Users/meri2/.conda/envs/MMRotate/lib/site-packages/mmcv/runner/epoch_based_runner.py?line=125'>126</a>\u001b[0m                 \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m--> <a href='file:///c%3A/Users/meri2/.conda/envs/MMRotate/lib/site-packages/mmcv/runner/epoch_based_runner.py?line=126'>127</a>\u001b[0m             epoch_runner(data_loaders[i], \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    <a href='file:///c%3A/Users/meri2/.conda/envs/MMRotate/lib/site-packages/mmcv/runner/epoch_based_runner.py?line=128'>129</a>\u001b[0m time\u001b[39m.\u001b[39msleep(\u001b[39m1\u001b[39m)  \u001b[39m# wait for some hooks like loggers to finish\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/meri2/.conda/envs/MMRotate/lib/site-packages/mmcv/runner/epoch_based_runner.py?line=129'>130</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcall_hook(\u001b[39m'\u001b[39m\u001b[39mafter_run\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\meri2\\.conda\\envs\\MMRotate\\lib\\site-packages\\mmcv\\runner\\epoch_based_runner.py:51\u001b[0m, in \u001b[0;36mEpochBasedRunner.train\u001b[1;34m(self, data_loader, **kwargs)\u001b[0m\n\u001b[0;32m     <a href='file:///c%3A/Users/meri2/.conda/envs/MMRotate/lib/site-packages/mmcv/runner/epoch_based_runner.py?line=48'>49</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcall_hook(\u001b[39m'\u001b[39m\u001b[39mbefore_train_iter\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m     <a href='file:///c%3A/Users/meri2/.conda/envs/MMRotate/lib/site-packages/mmcv/runner/epoch_based_runner.py?line=49'>50</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrun_iter(data_batch, train_mode\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m---> <a href='file:///c%3A/Users/meri2/.conda/envs/MMRotate/lib/site-packages/mmcv/runner/epoch_based_runner.py?line=50'>51</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcall_hook(\u001b[39m'\u001b[39;49m\u001b[39mafter_train_iter\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m     <a href='file:///c%3A/Users/meri2/.conda/envs/MMRotate/lib/site-packages/mmcv/runner/epoch_based_runner.py?line=51'>52</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iter \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m     <a href='file:///c%3A/Users/meri2/.conda/envs/MMRotate/lib/site-packages/mmcv/runner/epoch_based_runner.py?line=53'>54</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcall_hook(\u001b[39m'\u001b[39m\u001b[39mafter_train_epoch\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\meri2\\.conda\\envs\\MMRotate\\lib\\site-packages\\mmcv\\runner\\base_runner.py:309\u001b[0m, in \u001b[0;36mBaseRunner.call_hook\u001b[1;34m(self, fn_name)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/meri2/.conda/envs/MMRotate/lib/site-packages/mmcv/runner/base_runner.py?line=301'>302</a>\u001b[0m \u001b[39m\"\"\"Call all hooks.\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/meri2/.conda/envs/MMRotate/lib/site-packages/mmcv/runner/base_runner.py?line=302'>303</a>\u001b[0m \n\u001b[0;32m    <a href='file:///c%3A/Users/meri2/.conda/envs/MMRotate/lib/site-packages/mmcv/runner/base_runner.py?line=303'>304</a>\u001b[0m \u001b[39mArgs:\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/meri2/.conda/envs/MMRotate/lib/site-packages/mmcv/runner/base_runner.py?line=304'>305</a>\u001b[0m \u001b[39m    fn_name (str): The function name in each hook to be called, such as\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/meri2/.conda/envs/MMRotate/lib/site-packages/mmcv/runner/base_runner.py?line=305'>306</a>\u001b[0m \u001b[39m        \"before_train_epoch\".\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/meri2/.conda/envs/MMRotate/lib/site-packages/mmcv/runner/base_runner.py?line=306'>307</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/meri2/.conda/envs/MMRotate/lib/site-packages/mmcv/runner/base_runner.py?line=307'>308</a>\u001b[0m \u001b[39mfor\u001b[39;00m hook \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_hooks:\n\u001b[1;32m--> <a href='file:///c%3A/Users/meri2/.conda/envs/MMRotate/lib/site-packages/mmcv/runner/base_runner.py?line=308'>309</a>\u001b[0m     \u001b[39mgetattr\u001b[39;49m(hook, fn_name)(\u001b[39mself\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\meri2\\.conda\\envs\\MMRotate\\lib\\site-packages\\mmcv\\runner\\hooks\\optimizer.py:163\u001b[0m, in \u001b[0;36mGradientCumulativeOptimizerHook.after_train_iter\u001b[1;34m(self, runner)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/meri2/.conda/envs/MMRotate/lib/site-packages/mmcv/runner/hooks/optimizer.py?line=160'>161</a>\u001b[0m loss \u001b[39m=\u001b[39m runner\u001b[39m.\u001b[39moutputs[\u001b[39m'\u001b[39m\u001b[39mloss\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m    <a href='file:///c%3A/Users/meri2/.conda/envs/MMRotate/lib/site-packages/mmcv/runner/hooks/optimizer.py?line=161'>162</a>\u001b[0m loss \u001b[39m=\u001b[39m loss \u001b[39m/\u001b[39m loss_factor\n\u001b[1;32m--> <a href='file:///c%3A/Users/meri2/.conda/envs/MMRotate/lib/site-packages/mmcv/runner/hooks/optimizer.py?line=162'>163</a>\u001b[0m loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[0;32m    <a href='file:///c%3A/Users/meri2/.conda/envs/MMRotate/lib/site-packages/mmcv/runner/hooks/optimizer.py?line=164'>165</a>\u001b[0m \u001b[39mif\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mevery_n_iters(runner, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcumulative_iters)\n\u001b[0;32m    <a href='file:///c%3A/Users/meri2/.conda/envs/MMRotate/lib/site-packages/mmcv/runner/hooks/optimizer.py?line=165'>166</a>\u001b[0m         \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mis_last_iter(runner)):\n\u001b[0;32m    <a href='file:///c%3A/Users/meri2/.conda/envs/MMRotate/lib/site-packages/mmcv/runner/hooks/optimizer.py?line=167'>168</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgrad_clip \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\meri2\\.conda\\envs\\MMRotate\\lib\\site-packages\\torch\\_tensor.py:363\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/meri2/.conda/envs/MMRotate/lib/site-packages/torch/_tensor.py?line=353'>354</a>\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[0;32m    <a href='file:///c%3A/Users/meri2/.conda/envs/MMRotate/lib/site-packages/torch/_tensor.py?line=354'>355</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    <a href='file:///c%3A/Users/meri2/.conda/envs/MMRotate/lib/site-packages/torch/_tensor.py?line=355'>356</a>\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[0;32m    <a href='file:///c%3A/Users/meri2/.conda/envs/MMRotate/lib/site-packages/torch/_tensor.py?line=356'>357</a>\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/meri2/.conda/envs/MMRotate/lib/site-packages/torch/_tensor.py?line=360'>361</a>\u001b[0m         create_graph\u001b[39m=\u001b[39mcreate_graph,\n\u001b[0;32m    <a href='file:///c%3A/Users/meri2/.conda/envs/MMRotate/lib/site-packages/torch/_tensor.py?line=361'>362</a>\u001b[0m         inputs\u001b[39m=\u001b[39minputs)\n\u001b[1;32m--> <a href='file:///c%3A/Users/meri2/.conda/envs/MMRotate/lib/site-packages/torch/_tensor.py?line=362'>363</a>\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs)\n",
      "File \u001b[1;32mc:\\Users\\meri2\\.conda\\envs\\MMRotate\\lib\\site-packages\\torch\\autograd\\__init__.py:173\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/meri2/.conda/envs/MMRotate/lib/site-packages/torch/autograd/__init__.py?line=167'>168</a>\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[0;32m    <a href='file:///c%3A/Users/meri2/.conda/envs/MMRotate/lib/site-packages/torch/autograd/__init__.py?line=169'>170</a>\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/meri2/.conda/envs/MMRotate/lib/site-packages/torch/autograd/__init__.py?line=170'>171</a>\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/meri2/.conda/envs/MMRotate/lib/site-packages/torch/autograd/__init__.py?line=171'>172</a>\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> <a href='file:///c%3A/Users/meri2/.conda/envs/MMRotate/lib/site-packages/torch/autograd/__init__.py?line=172'>173</a>\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/meri2/.conda/envs/MMRotate/lib/site-packages/torch/autograd/__init__.py?line=173'>174</a>\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[0;32m    <a href='file:///c%3A/Users/meri2/.conda/envs/MMRotate/lib/site-packages/torch/autograd/__init__.py?line=174'>175</a>\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Trying to backward through the graph a second time (or directly access saved tensors after they have already been freed). Saved intermediate values of the graph are freed when you call .backward() or autograd.grad(). Specify retain_graph=True if you need to backward through the graph a second time or if you need to access saved tensors after calling backward."
     ]
    }
   ],
   "source": [
    "main(args)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "40c2207bf340c57e2abd749771f5a430f07aaa9ea3b18adc08a8e5fdda3822d0"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('MMRotate')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
