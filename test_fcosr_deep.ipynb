{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.stdout.fileno = lambda : 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from testing_fns import setup, load_image\n",
    "from viz import format_maps\n",
    "from mmrotate.models import build_loss\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-10 12:26:46,658 - mmrotate - INFO - Environment info:\n",
      "------------------------------------------------------------\n",
      "sys.platform: win32\n",
      "Python: 3.9.12 (main, Apr  4 2022, 05:22:27) [MSC v.1916 64 bit (AMD64)]\n",
      "CUDA available: True\n",
      "GPU 0: NVIDIA GeForce RTX 3070 Laptop GPU\n",
      "CUDA_HOME: C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v11.3\n",
      "NVCC: Cuda compilation tools, release 11.3, V11.3.58\n",
      "MSVC: Microsoft (R) C/C++ Optimizing Compiler Version 19.29.30138 for x64\n",
      "GCC: n/a\n",
      "PyTorch: 1.11.0\n",
      "PyTorch compiling details: PyTorch built with:\n",
      "  - C++ Version: 199711\n",
      "  - MSVC 192829337\n",
      "  - Intel(R) Math Kernel Library Version 2020.0.2 Product Build 20200624 for Intel(R) 64 architecture applications\n",
      "  - Intel(R) MKL-DNN v2.5.2 (Git Hash a9302535553c73243c632ad3c4c80beec3d19a1e)\n",
      "  - OpenMP 2019\n",
      "  - LAPACK is enabled (usually provided by MKL)\n",
      "  - CPU capability usage: AVX2\n",
      "  - CUDA Runtime 11.3\n",
      "  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37\n",
      "  - CuDNN 8.2\n",
      "  - Magma 2.5.4\n",
      "  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.3, CUDNN_VERSION=8.2.0, CXX_COMPILER=C:/cb/pytorch_1000000000000/work/tmp_bin/sccache-cl.exe, CXX_FLAGS=/DWIN32 /D_WINDOWS /GR /EHsc /w /bigobj -DUSE_PTHREADPOOL -openmp:experimental -IC:/cb/pytorch_1000000000000/work/mkl/include -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOCUPTI -DUSE_FBGEMM -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.11.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=OFF, USE_MPI=OFF, USE_NCCL=OFF, USE_NNPACK=OFF, USE_OPENMP=ON, USE_ROCM=OFF, \n",
      "\n",
      "TorchVision: 0.12.0\n",
      "OpenCV: 4.5.5\n",
      "MMCV: 1.5.0\n",
      "MMCV Compiler: MSVC 192930138\n",
      "MMCV CUDA Compiler: 11.3\n",
      "MMRotate: 0.3.0+3051333\n",
      "------------------------------------------------------------\n",
      "\n",
      "2022-05-10 12:26:47,459 - mmrotate - INFO - Distributed training: False\n",
      "2022-05-10 12:26:48,306 - mmrotate - INFO - Config:\n",
      "image_size = (1024, 1024)\n",
      "angle_version = 'oc'\n",
      "dataset_type = 'DOTADataset'\n",
      "data_root = 'C:/Users/meri2/Documents/DOTA_1.0/split_ms_dota/'\n",
      "img_norm_cfg = dict(\n",
      "    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)\n",
      "train_pipeline = [\n",
      "    dict(type='LoadImageFromFile'),\n",
      "    dict(type='LoadAnnotations', with_bbox=True),\n",
      "    dict(type='RResize', img_scale=(1024, 1024)),\n",
      "    dict(type='RRandomFlip', flip_ratio=0.5, version='oc'),\n",
      "    dict(\n",
      "        type='Normalize',\n",
      "        mean=[123.675, 116.28, 103.53],\n",
      "        std=[58.395, 57.12, 57.375],\n",
      "        to_rgb=True),\n",
      "    dict(type='Pad', size_divisor=32),\n",
      "    dict(type='DefaultFormatBundle'),\n",
      "    dict(type='Collect', keys=['img', 'gt_bboxes', 'gt_labels'])\n",
      "]\n",
      "test_pipeline = [\n",
      "    dict(type='LoadImageFromFile'),\n",
      "    dict(\n",
      "        type='MultiScaleFlipAug',\n",
      "        img_scale=(1024, 1024),\n",
      "        flip=False,\n",
      "        transforms=[\n",
      "            dict(type='RResize'),\n",
      "            dict(\n",
      "                type='Normalize',\n",
      "                mean=[123.675, 116.28, 103.53],\n",
      "                std=[58.395, 57.12, 57.375],\n",
      "                to_rgb=True),\n",
      "            dict(type='Pad', size_divisor=32),\n",
      "            dict(type='DefaultFormatBundle'),\n",
      "            dict(type='Collect', keys=['img'])\n",
      "        ])\n",
      "]\n",
      "data = dict(\n",
      "    samples_per_gpu=1,\n",
      "    workers_per_gpu=2,\n",
      "    train=dict(\n",
      "        type='DOTADataset',\n",
      "        ann_file=\n",
      "        'C:/Users/meri2/Documents/DOTA_1.0/split_ms_dota/trainval/annfiles/',\n",
      "        img_prefix=\n",
      "        'C:/Users/meri2/Documents/DOTA_1.0/split_ms_dota/trainval/images/',\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(type='LoadAnnotations', with_bbox=True),\n",
      "            dict(type='RResize', img_scale=(1024, 1024)),\n",
      "            dict(type='RRandomFlip', flip_ratio=0.5, version='oc'),\n",
      "            dict(\n",
      "                type='Normalize',\n",
      "                mean=[123.675, 116.28, 103.53],\n",
      "                std=[58.395, 57.12, 57.375],\n",
      "                to_rgb=True),\n",
      "            dict(type='Pad', size_divisor=32),\n",
      "            dict(type='DefaultFormatBundle'),\n",
      "            dict(type='Collect', keys=['img', 'gt_bboxes', 'gt_labels'])\n",
      "        ]),\n",
      "    val=dict(\n",
      "        type='DOTADataset',\n",
      "        ann_file=\n",
      "        'C:/Users/meri2/Documents/DOTA_1.0/split_ms_dota/trainval/annfiles/',\n",
      "        img_prefix=\n",
      "        'C:/Users/meri2/Documents/DOTA_1.0/split_ms_dota/trainval/images/',\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(\n",
      "                type='MultiScaleFlipAug',\n",
      "                img_scale=(1024, 1024),\n",
      "                flip=False,\n",
      "                transforms=[\n",
      "                    dict(type='RResize'),\n",
      "                    dict(\n",
      "                        type='Normalize',\n",
      "                        mean=[123.675, 116.28, 103.53],\n",
      "                        std=[58.395, 57.12, 57.375],\n",
      "                        to_rgb=True),\n",
      "                    dict(type='Pad', size_divisor=32),\n",
      "                    dict(type='DefaultFormatBundle'),\n",
      "                    dict(type='Collect', keys=['img'])\n",
      "                ])\n",
      "        ]),\n",
      "    test=dict(\n",
      "        type='DOTADataset',\n",
      "        ann_file='C:/Users/meri2/Documents/DOTA_1.0/split_ms_dota/test/images/',\n",
      "        img_prefix=\n",
      "        'C:/Users/meri2/Documents/DOTA_1.0/split_ms_dota/test/images/',\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(\n",
      "                type='MultiScaleFlipAug',\n",
      "                img_scale=(1024, 1024),\n",
      "                flip=False,\n",
      "                transforms=[\n",
      "                    dict(type='RResize'),\n",
      "                    dict(\n",
      "                        type='Normalize',\n",
      "                        mean=[123.675, 116.28, 103.53],\n",
      "                        std=[58.395, 57.12, 57.375],\n",
      "                        to_rgb=True),\n",
      "                    dict(type='Pad', size_divisor=32),\n",
      "                    dict(type='DefaultFormatBundle'),\n",
      "                    dict(type='Collect', keys=['img'])\n",
      "                ])\n",
      "        ]))\n",
      "evaluation = dict(interval=36, metric='mAP')\n",
      "optimizer = dict(type='SGD', lr=0.001, momentum=0.9, weight_decay=0.0001)\n",
      "optimizer_config = dict(grad_clip=dict(max_norm=35, norm_type=2))\n",
      "lr_config = dict(\n",
      "    policy='step',\n",
      "    warmup='linear',\n",
      "    warmup_iters=500,\n",
      "    warmup_ratio=0.3333333333333333,\n",
      "    step=[24, 33])\n",
      "runner = dict(type='EpochBasedRunner', max_epochs=36)\n",
      "checkpoint_config = dict(interval=1)\n",
      "log_config = dict(interval=1, hooks=[dict(type='TextLoggerHook')])\n",
      "dist_params = dict(backend='nccl')\n",
      "log_level = 'INFO'\n",
      "load_from = None\n",
      "resume_from = None\n",
      "workflow = [('train', 1)]\n",
      "opencv_num_threads = 0\n",
      "mp_start_method = 'fork'\n",
      "model = dict(\n",
      "    type='FCOSR',\n",
      "    backbone=dict(\n",
      "        type='ResNeXt',\n",
      "        groups=32,\n",
      "        base_width=4,\n",
      "        depth=50,\n",
      "        num_stages=4,\n",
      "        out_indices=(1, 2, 3),\n",
      "        frozen_stages=1,\n",
      "        style='pytorch',\n",
      "        init_cfg=dict(\n",
      "            type='Pretrained', checkpoint='torchvision://resnext50_32x4d')),\n",
      "    neck=dict(\n",
      "        type='FPN',\n",
      "        in_channels=[512, 1024, 2048],\n",
      "        out_channels=256,\n",
      "        start_level=0,\n",
      "        num_outs=5,\n",
      "        add_extra_convs='on_output',\n",
      "        relu_before_extra_convs=True),\n",
      "    bbox_head=dict(\n",
      "        type='FCOSRHead',\n",
      "        num_classes=15,\n",
      "        in_channels=256,\n",
      "        feat_channels=256,\n",
      "        stacked_convs=4,\n",
      "        strides=(8, 16, 32, 64, 128),\n",
      "        regress_ranges=((-1, 64), (64, 128), (128, 256), (256, 512),\n",
      "                        (512, 100000000)),\n",
      "        conv_cfg=dict(type='Conv2d'),\n",
      "        norm_cfg=dict(type='GN', num_groups=32, requires_grad=True),\n",
      "        assigner=dict(\n",
      "            type='GaussianAssigner',\n",
      "            gauss_factor=12.0,\n",
      "            inside_ellipsis_thresh=0.23,\n",
      "            epsilon=1e-06),\n",
      "        cls_loss=dict(\n",
      "            type='QualityFocalLoss',\n",
      "            use_sigmoid=True,\n",
      "            beta=2.0,\n",
      "            reduction='mean',\n",
      "            loss_weight=1.0),\n",
      "        cls_scores='iou',\n",
      "        reg_loss=dict(type='ProbiouLoss', mode='l1', loss_weight=0.0),\n",
      "        reg_weights='iou',\n",
      "        init_cfg=dict(\n",
      "            type='Normal',\n",
      "            layer='Conv2d',\n",
      "            std=0.01,\n",
      "            override=dict(\n",
      "                type='Normal',\n",
      "                name='cls_logits_conv',\n",
      "                std=0.01,\n",
      "                bias_prob=0.01))),\n",
      "    train_cfg=dict(gamma=2.0, alpha=0.25),\n",
      "    test_cfg=dict(\n",
      "        nms_pre=2000,\n",
      "        min_bbox_size=8,\n",
      "        score_thr=0.1,\n",
      "        nms=0.1,\n",
      "        max_per_img=2000,\n",
      "        extra_nms=0.85,\n",
      "        rotations=[]))\n",
      "work_dir = './work_dirs\\fcosr_res50_32x4d_fpn_3x_dota10_single'\n",
      "gpu_ids = range(0, 1)\n",
      "\n",
      "2022-05-10 12:26:48,307 - mmrotate - INFO - Set random seed to 42, deterministic: True\n",
      "2022-05-10 12:26:48,680 - mmrotate - INFO - initialize ResNeXt with init_cfg {'type': 'Pretrained', 'checkpoint': 'torchvision://resnext50_32x4d'}\n",
      "2022-05-10 12:26:48,681 - mmcv - INFO - load model from: torchvision://resnext50_32x4d\n",
      "2022-05-10 12:26:48,682 - mmcv - INFO - load checkpoint from torchvision path: torchvision://resnext50_32x4d\n",
      "2022-05-10 12:26:48,817 - mmcv - WARNING - The model and loaded state dict do not match exactly\n",
      "\n",
      "unexpected key in source state_dict: fc.weight, fc.bias\n",
      "\n",
      "2022-05-10 12:26:48,854 - mmrotate - INFO - initialize FPN with init_cfg {'type': 'Xavier', 'layer': 'Conv2d', 'distribution': 'uniform'}\n",
      "2022-05-10 12:26:48,885 - mmrotate - INFO - initialize FCOSRHead with init_cfg {'type': 'Normal', 'layer': 'Conv2d', 'std': 0.01, 'override': {'type': 'Normal', 'name': 'cls_logits_conv', 'std': 0.01, 'bias_prob': 0.01}}\n"
     ]
    }
   ],
   "source": [
    "model, datasets, cfg, timestamp, meta = setup(\"configs/fcosr/fcosr_res50_32x4d_fpn_3x_dota10_single.py\")\n",
    "\n",
    "model.bbox_head.cls_loss_fn = build_loss(\n",
    "    dict(type='QualityFocalLoss', use_sigmoid=True, beta=2.0, reduction='none', loss_weight=1.0))\n",
    "model.bbox_head.reg_loss_fn = build_loss(\n",
    "    dict(type='ProbiouLoss', mode='l1', loss_weight=0.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "kwargs = load_image(datasets, 0)\n",
    "\n",
    "feature_maps = model.extract_feats([kwargs['img']])[0]\n",
    "cls_logits, rbox_preds = model.bbox_head.forward_multi_lvl(feature_maps)\n",
    "fm_shapes = [(fm.size(2), fm.size(3)) for fm in feature_maps]\n",
    "positions, strides, regress_ranges = model.bbox_head.compute_auxiliaries(fm_shapes)\n",
    "cls_targets, cls_scores, reg_targets, reg_weights = model.bbox_head.compute_targets(\n",
    "    kwargs['gt_bboxes'], kwargs['gt_labels'], rbox_preds, positions, strides, regress_ranges)\n",
    "# format classification components\n",
    "cls_logits = cls_logits.flatten(0, 1)  # B, P, C -> BP, C\n",
    "cls_targets = cls_targets.flatten()  # B, P -> BP\n",
    "cls_scores = cls_scores.flatten()  # B, P -> BP\n",
    "# format regression components\n",
    "rbox_preds = rbox_preds.flatten(0, 1)  # B, P, 5 -> BP, 5\n",
    "reg_targets = reg_targets.flatten(0, 1)  # B, P, 5 -> BP, 5\n",
    "reg_weights = reg_weights.flatten()  # B, P -> BP\n",
    "# filter on prediction being a detection\n",
    "detection_mask = cls_targets != cls_targets.max()\n",
    "rbox_preds = rbox_preds[detection_mask]\n",
    "reg_targets = reg_targets[detection_mask]\n",
    "reg_weights = reg_weights[detection_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.3416,  2.2137, 11.2083,  7.7931, -0.0305],\n",
      "        [-1.7782, -1.2409, 10.3124,  7.6003, -0.0376],\n",
      "        [ 0.8997, -1.1670, 11.0492,  7.7701, -0.0703]],\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([[6.1304e+02, 3.3284e+02, 9.4340e+00, 1.4946e+01, 5.5860e-01],\n",
      "        [6.2932e+02, 2.9547e+02, 8.5437e+00, 1.5005e+01, 3.6717e-01],\n",
      "        [6.3866e+02, 2.9964e+02, 1.0636e+01, 1.7989e+01, 4.0489e-01]])\n",
      "tensor([[612., 332.],\n",
      "        [628., 292.],\n",
      "        [636., 300.]])\n"
     ]
    }
   ],
   "source": [
    "print(rbox_preds[:3])\n",
    "print(reg_targets[:3])\n",
    "print(positions[detection_mask][:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "40c2207bf340c57e2abd749771f5a430f07aaa9ea3b18adc08a8e5fdda3822d0"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('MMRotate')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
